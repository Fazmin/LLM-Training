### This just simple tokenizer takes a string of text and breaks it up into individual tokens. 
 - The settings can be adjusted to split on different characters
 - Options for remove or not remove punctuation, 
 - Option to convert all text to lowercase or leave it as is.

Please note that this is a very basic tokenizer I wrote to test out the process.
For more complex use cases such as handling different languages, contractions, or more advanced tokenization strategies, consider using established libraries like NLTK, SpaCy, or Hugging Face's Tokenizers.